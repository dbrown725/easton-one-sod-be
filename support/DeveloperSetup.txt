
****************************************************		
Project Mgmt Kanban and backlog
****************************************************		
	https://easton-one-code-monkeys.monday.com/
	
****************************************************		
Set up MySql
****************************************************

	Install MySql and MySql Workbench
		https://www.simplilearn.com/tutorials/mysql-tutorial/mysql-workbench-installation
	
	Tables
		Once you have installed MySQL and have a schema to work with do the following.
			- from the back end's workspace ../support directory
				create tables using tableCreation.sql
				Import into the user table using userTableData.csv
				Import into the song table the latest csv. Not checked in, see another developer for a copy.

****************************************************		
Set up Elastic search/Kibana
****************************************************

	Install both locally	
		Ubuntu specific instructions: https://phoenixnap.com/kb/how-to-install-elk-stack-on-ubuntu
		Windows (untested): https://nunogois-dev.medium.com/elasticsearch-kibana-7-10-setup-on-windows-4a7bbbef28ac
		
		If ElasticSearch/Kibana machine is different from local development machine
			Updated /etc/elasticsearch/elasticsearch.yml
			To allow all local IPs to be accessible
				network.host:0.0.0.0
				discovery.type: single-node
				
			Updated /etc/kibana/kibana.yml
			To allow external access
				server.host: "0.0.0.0"	
	
	Start both
		Ubuntu specific	
			sudo systemctl start elasticsearch.service	
			sudo systemctl start kibana
			
	Open Kibana - 		
		http://localhost:5601	
		If you get a not found wait a few minutes and refresh browser

	Install data (assumes data has been loaded already into MySQL "song" table)
		In MySQL workbench
		
			Old Method
				Right click song table
				Select "Table Data Export Wizard"
				Leave column defaults and click Next
				Select "CSV" and enter a path to where the ".../songExport.csv" should go
				Make sure "Field Separator" is set to comma
				Click Next
				Click Next
				If no errors Click Next
				Finish
				Inspect generated file
				
			New Method (includes first_name and last_name from the user table)
				Run the below queries one by one and export each resultset to a separate file. To export: "Result Grid" click on Export icon.
					Make sure the bottom left hand corner input "Format" is set to CSV.
					
						select song.id, actual_band_name, actual_song_name, youtube_title, youtube_url, youtube_playlist, user_id, 
								user.first_name as user_first_name, user.last_name as user_last_name, user.avatar_color as user_avatar_color 
								from eastonOneSOD.song join eastonOneSOD.user on song.user_id = user.id 
						        where song.id <= 2000
						        order by song.id asc;
						        
						select song.id, actual_band_name, actual_song_name, youtube_title, youtube_url, youtube_playlist, user_id, 
								user.first_name as user_first_name, user.last_name as user_last_name, user.avatar_color as user_avatar_color 
								from eastonOneSOD.song join eastonOneSOD.user on song.user_id = user.id 
						        where song.id > 2000 and song.id <= 4000
						        order by song.id asc;
						        
						select song.id, actual_band_name, actual_song_name, youtube_title, youtube_url, youtube_playlist, user_id, 
								user.first_name as user_first_name, user.last_name as user_last_name, user.avatar_color as user_avatar_color 
								from eastonOneSOD.song join eastonOneSOD.user on song.user_id = user.id 
						        where song.id > 4000 and song.id <= 6000
						        order by song.id asc;	

				Concatenate the rows from the three csv files into one csv file (for example songExport.csv) which will be used later to load ElasticSearch.
			
	Back to Kibana http://localhost:5601		
		Left Nav -> Analytics -> Dashboard
		Should be a link to "Install some sample data". First time in the screen might be a little different.
		Click the "Upload File" tab
		Click "Select or drag and drop a file"
		Select the previously "song" table exported csv file (for example songExport.csv)
		Analysis of the first 1000 rows is displayed.
		Bottom left hand corner of screen Click the Import" button
		Click the "Advanced" tab
			Enter Index Name: "song_of_the_day"
			Remove all references to create_time and modify_time from "Mappings" and "Ingest pipeline"
			In the "Ingest pipeline" section add the following to the bottom of the "processors" array
				{
				  "set": {
				    "field": "_id",
				    "value": "{{id}}"
				  }
				}
		Click Import		
		I got the below error but the generated index seems ok. Might be related to the fact that I previously had a song_of_the_day index or there could be some issue with the imported data. In step 5 "Creating index pattern"
			Error creating index pattern
			{"name":"DuplicateDataViewError"}
	
	Test
		Left nav -> Analytics -> Discover
			Make sure the "song_of_the_day" index is selected in the upper left hand corner grey drop down.
			You should be able to see a bunch of records in right hand pane. Mine has dispalys "5239" hits
			Enter a phrase like "Rolling" in the Search bar and hit your key board Enter key.
			Results and hit count should change. Words that match will be highlighted in yellow.
			
		Left nav -> Management -> Dev Tools	
			You can submit queries like the below. Useful for when figuring out what needs to go ina java written query.
				GET /song_of_the_day/_doc/_search
				{
				  "query" : {
				    "match_phrase" : {
				      "youtube_title" : "Ludella Black"
				    }
				  }
				}

				GET /song_of_the_day/_doc/_search
				{
				  "query": {
				    "bool": {
				      "must": [
					{
					  "match": {
					    "youtube_title": {
					      "query": "Stones",
					      "boost": 3
					    }
					  }
					},
					{
					  "match": {
					    "youtube_title": "Rolling"
					  }
					}
				      ]
				    }
				  },
				  "highlight": {
				    "fields": {
				      "YouTube Title": {}
				    }
				  }
				} 
	Complete!
		Update your backend application.properties "es.hostname" property to "localhost" or an ip address if your backend and elastic search are on separate boxes 		
	
	DEV tools for later index management
		Left nav -> Management -> Dev Tools
		In Left pane
			Create index
				PUT /song_of_the_day
			Get index info
				GET /song_of_the_day
			Delete an index
				DELETE /song_of_the_day
			Delete a document by id
				DELETE /song_of_the_day/_doc/156
		
****************************************************
*********** Local tech Stack ***********************
****************************************************
	Ubuntu 20.04.4 LTS (can be anything, windows, linux, etc....)
	NPM 8.18.0 (any newer version is probably good)
	Node 18.8.0 (any newer version is probably good)
	Java OpenJDK 64-Bit Server VM (build 11.0.17+8-post-Ubuntu-1ubuntu220.04, mixed mode, sharing) (any Java 11 will work probably)
	Elastic Search 7.17.5
	Maven
	Kibana 7.17.5
	Ionic React
	Spring-boot
	JPA
	Google Firebase for Bearer token based Authentication

****************************************************
*********** Front End 	      ***********************
****************************************************
	Install Node on your machine if it isn't already installed
	Checkout github repo
	navigate to project directory
	Update src/index.tsx, change HttpLink to have your backend app's uri
	Update firebase.js with proper firebaseConfig values you have received from another developer
	npm install
	npm run start 
	http://localhost:3000/	
	
****************************************************
*********** Back End 	      ***********************
****************************************************
	Checkout github repo
	Update application properties
		- set spring.datasource.url to point to your Mysql
		- set es.hostname to point to you Elastic Search install
		- set security.allowed-origins to your local ip address
		- set Email related properties with values you have received from another developer
	Update firebase_config.json with proper values you have received from another developer
	Run a Maven package build
	From a terminal run ./run_be.sh to start up the app. If on Windows you should create a .bat file
	Use the graphiql web app to run some tests. See ../support/graphiql_test_cases.txt for testing Instructions and test cases.	

****************************************************
*********** Backend testing with Auth **************
****************************************************
	Postman - see below article
		https://alex-wasik.medium.com/using-postman-to-fetch-a-firebase-token-9d151670c05b

	Graphiql - need to install in Chrome Extension "ModHeader - Modify HTTP headers", see directions below
		https://www.webnots.com/how-to-view-and-edit-http-request-and-response-headers-in-chrome
		Name: Authorization Value: Bearer <idToken>
		Note: <idToken> can be retrieved from Postman, see above Postman article.
		############################################################################################################
		############################################################################################################
		################ WARNING:  Authorization Value: Bearer <idToken> will be sent on every request from Chrome
		################    Delete the values from the ModHeader Chrome extension after completing testing otherwise
		################      your logins to other accounts (like your bank) using this browser will fail.
		############################################################################################################
		############################################################################################################

****************************************************
*********** Random Notes     ***********************
****************************************************	
	avatar color starting point: https://codepen.io/peterbartha/pen/BKxGPK

- Spring boot Firebase

		- https://medium.com/@purikunal22/securing-springboot-api-using-firebase-authentication-16d72dd250cc
			https://github.com/kunal52/springbootfirebaseauth

		- https://alex-wasik.medium.com/using-postman-to-fetch-a-firebase-token-9d151670c05b

- React Firebase
		- https://blog.logrocket.com/user-authentication-firebase-react-apps/
			https://github.com/atharvadeosthale/firebase-auth-article/blob/master/src/Login.js
